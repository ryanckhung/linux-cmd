Control groups, known as cgroups, are a feature of the Linux kernel allowing the limitation, accounting, and isolation of resources used by groups of processes and their subgroups.
Cgroups are a fundamental feature of various Operating System level virtualization mechanisms, such as OpenVZ and LXC.
Cgroups allow the limitation of memory, disk I/O, and network usage for a group of processes. In addition, cgroups may set usage quotas, and prioritize a process group to receive more CPU time or memory than other groups. 
Containers benefit from cgroups primarily because they allow system resources to be limited for processes grouped by a container.
Path: /sys/fs/cgroup

> sudo -i                           (switch to root user)
> apt-get install -y cgroup-tools   (install the cgroup)
> lscgroup                          (list all cgroups in the system)
> cat /proc/<PID>/cgroup            (list cgroups associated with a process)
> cat  /proc/1/cgroup
> cd /sys/fs/cgroup/freezer
> mkdir mycgroup
> cd mycgroup
> echo <pid> >> tasks               (add the porcess id to the tasks file)
> echo FROZEN > freezer.state       (make the process with pid stated in tasks file to be frozen)
> echo THAWED > freezer.state       (make the process with pid stated in tasks file return normal)
(read the lab for more)


Namespaces are a feature of the Linux kernel allowing groups of processes to have limited visibility of the host system resources.
Namespaces isolate processes from one container to prevent them from modifying the hostname, network interfaces, or mounts for processes running in other containers.
Processes running inside a namespace are aware of any changes in the local namespaced system resources, however, such changes will not be visible to other processes or other namespaces.


UnionFS is a feature found in the Linux, FreeBSD and NetBSD kernels, allowing the overlay of separate transparent file systems to produce an apparent single unified file system.
When the content of several file systems, called branches, are virtually stacked, their contents appear to be merged, however, physically, they remain separate.
However, virtually, through the unified file system, it appears as if the original file has been modified instead.
In a container, unionfs allows for changes to be made to the container image at runtime. The container image and other writable file systems are all stacked into a unionfs when the container is created and is running. 

[generally speaking: cgroup - limit resource; namespace - provide isolation; UnionFS - merging data]

Operating System level virtualization is typically used to limit usage and securely isolate resources shared between multiple programs or users, and to separate programs to run in their own assigned virtual environments for better security and resource management.
Chroot is a mechanism implementing OS-level virtualization.
Chroot operates on a UNIX-like operating system by changing the apparent root directory of a process and its children. This apparent root directory is no longer the real root directory of the operating system, it is a virtual root directory - commonly referred to as a chrooted directory. 


Type of virtualization   (history - pay attention to LXC):
1. Chroot
Chroot is a mechanism implementing OS-level virtualization. It was first introduced on UNIX Version 7 in 1979, then in 1982 it was added to BSD.
Chroot operates on a UNIX-like operating system by changing the apparent root directory of a process and its children. This apparent root directory is no longer the real root directory of the operating system, it is a virtual root directory - commonly referred to as a chrooted directory.
2. FreeBSD Jail
A FreeBSD jail is a mechanism implementing OS-level virtualization with very little overhead. It was first introduced in 2000 on FreeBSD systems.
FreeBSD jail allows for the partitioning of a FreeBSD system into many independent systems, called jails. They share the same kernel, but virtualize the system’s files and resources for improved security and administration through clean isolation between services.
3. Solaris Zone
A Solaris zone is a mechanism implementing OS-level virtualization. It was first introduced in 2004 on Solaris 10 systems.
4. OpenVZ
OpenVZ is a mechanism implementing OS-level virtualization; it was first introduced in 2005 on Linux systems.
OpenVZ allows a physical host to run multiple isolated virtual instances - called containers, virtual environments or virtual private servers. OpenVZ containers share the same kernel, and can only run Linux.
5. LXC
LXC, or Linux Containers, is a mechanism implementing OS-level virtualization; it was first introduced in 2008 on Linux systems.
LXC allows multiple isolated systems to run on a single Linux host, using chroot and cgroups, together with namespace isolation features of the Linux kernel to limit resources, set priorities, and isolate processes, the filesystem, network and users from the host operating system.
6. Systemd-nspawn
Systemd-nspawn is a mechanism implementing OS-level virtualization; it was first introduced in 2010 on Linux systems.


Container Runtime:
Docker is one of the most robust and complex container development and management platforms in the container industry. Although we list it here as a container runtime, Docker is a lot more than just a simple, or not so simple, container platform. The Docker platform supports a wide range of operations, from container image management to container lifecycle and runtime management.
The Docker client is the CLI tool that allows users to run docker commands against a Docker daemon running on a Docker host.
The Docker host is a system running the Docker daemon - called dockerd. The daemon is responsible for building, running, and distributing Docker containers. 
The Docker registries store Docker container images.
> sudo apt-get install -y docker.io
> sudo docker run hello-world           (deploy a hello world for test)

The key component required for the creation of a container image is the Dockerfile. It includes a set of instructions that are executed by the Docker daemon to build the image.
* FROM to initialize the image build and specify the base image used as starting point for the current build,
* COPY to populate the container’s filesystem with existing directories or files from the host system,
* RUN to execute commands that alter the base image and commit the changes,
* CMD to provide defaults for the running container,
* ENTRYPOINT to configure a container’s command line arguments by overriding defaults specified by CMD,
* LABEL to add metadata in a key-value pair format to the image,
* EXPOSE to specify the port number and protocol which should be published as options with the docker run command,
* ENV to set environment variables in a key-value pair format,
* VOLUME to mount storage in the container,
* USER to set the user name and possibly the group name at runtime.

command reference URL:
https://docs.docker.com/engine/reference/commandline/docker/
> docker image build
> docker image ls
> docker image prune    (Remove unused images)
> docker image push
> docker image pull
> docker image rm
> docker image inspect  (Display detailed information on one or more images)

some other example:
> sudo docker serach nginx
> sudo docker image pull nginx                                  (pull image from docker hub)
> sudo docker image pull myregistry.com:5000/alpine:latest      (Pull an image from a private registry, by specifying registry name, port number, image name and tag)
> sudo docker image ls                                          (list images cached in the local repository)
> sudo docker login                                             (will login to docker hub)
> sudo docker image push lfstudent/alpine:training              (push to docker hub)
> sudo docker image push myregistry.com:5000/alpine:training    (push to private registry)
> sudo docker image prune                                       (remove unused cached images from local repository)
> sudo docker image rm -f alpine:latest nginx:latest            (remove one or more cached images from local repository)
> sudo docker image inspect nginx                               (display image details)



Other container runtime, example:
LXC and LXD, Kata Containers, gVisor, Podman, runc, containerd, rkt, CRI-O

Container runtime provide platform for the management of container environments and their lifecycle. 
A container is a process running on the host system. This process is started by the container runtime from a container image, and the runtime provides a set of tools to manage the container process. The container is an isolated environment that encapsulates a running application, and it runs based on the configuration defined in the container image.
At runtime, virtualization features available at the kernel level are attached to the container process to help manage various aspects of the container’s virtual environment. Namespaces virtualize the container process’s PID, network, root, and users. Cgroups help set resource usage limits the container process can consume on the host system, and security contexts enforce permissions the container process has on the host system.
A container, as a runtime object, consumes the typical resources any running process would consume on a system: storage for the file system and any saved configuration files, CPU, memory, and networking to serve traffic to/from external clients, and other containers or devices on the system.



Docker, the most complex container platform, supports a wide range of container operations. 
Traditionally, there is a set of commands such as docker create, docker start, docker stop, docker restart, docker kill, docker remove that allow a user to alter the state of a container, together with docker ps for a listing of containers, docker logs to display container logs, docker inspect displays detailed information about an object, and docker stats displays resource usage.
> docker create
> docker start
> docker stop
> docker restart
> docker kill
> docker remove
> docker ps                 (list containers)
> docker logs               (display container logs)
> docker inspect            (display detailed info about an object)
> docker stats              (display resource usage)
> docker start              (start stopped containers)
> docker container start    (start stopped containers)
> docker container inspect  (display details about containers)
# command allo to interact with the processes running inside a container
> docker exec               (run cmd in a running container)
> docker container exec     (run cmd in a running container)
> docker pause              (pause processes inside one or more containers)
> docker container pause    (pause processes inside one or more containers)
> docker unpause            (unpause processes inside one or more containers)
> docker container unpause  (unpause processes inside one or more containers)
> docker run                (run a command in a new container)
> docker container run      (run a command in a new container)
> docker top                (lists processes running in a container)
> docker container top      (lists processes running in a container)


Lab 6.2
> sudo docker image pull alpine                                     (pull from docker hub)
> sudo docker image pull <private_registry>:<port>/image            (pull from private registry)
> sudo docker image ls                                              (list images available in the local repository)
> sudo docker container create -it alpine sh                        (create container from the image available in hte local repository; assume the container id begin with 6ac)
> sudo docker container start 6ac                                   (start the created container with a partial container id)
> sudo docker container ls                                          (list running containers)
> sudo docker container run -it --name myalpine alphine sh          (--name provide the name of the container, sh here is the cmd to be run)
(the above command will make it run inside the container; to quit press Ctrl p + Ctrl q)
> sudo docker container ls -a                                       (will list out both running and stopping containers)
> sudo docker container attach myalpine                             (make the running docker myalpine to be in attach mode (foreground))
> sudo docker container run -d alpine /bin/sh -c 'while [ 1 ]; do echo "hello world from container"; sleep 1; done' (/bin/sh -c '' is the cmd to be run)
> sudo docker container logs be9                                    (get the logs from the container, be9 is the short form of the container id)
> sudo docker container stop be9                                    (stop the running container only; the container still there)
> sudo docker container start be9                                   (start a stopped container)
> sudo docker container restart be9                                 (stop and start a container)
> sudo docker container pause be9                                   (pause a container)
> sudo docker container unpause be9                                 (unpause a container)
> sudo docker container rename original_name new_name               (rename a running container)
# remove a container: method 1
> sudo docker container stop hello_world
> sudo docker container rm hello_world
# remove a container: method 2
> sudo docker container rm -f myalpine
> sudo docker container run --rm --name new_name alpine ping -c 3 google.com        (--rm remove the container when nothing to run)
> sudo docker container run -it --env "WEB_HOST=172.168.1.1" --rm alpine sh
> sudo docker container exec dreamy_golick ip a                                     (execute a command inside a running container)
> sudo docker container run -d --restart=always --name web-always nginx             (awlays restrun when it's fail)
> sudo docker container run -d --restart=on-failure:3 --name web-on-failure nginx   (try 3 times to wake it up if it's fail)
> sudo docker container prune                                                       (kill all exited containers)

-it (TTY at interactive mode)
--name (provide the name of the container)
attach (make the running container in the attach mode)
-d (make the newly running container to run in detach mode)
logs, stop, start, restart, pause, unpause, rename
--rm (remove the container when it's going to exit)
--env (specify the environment)
-w (specify the workding directory of the container)
-h (specify the host name of the container)
--ulimit nproc=10 (limit the max user process for the container)
--cupset-cpus="0" (set the CPU going to run this container)
--memory "200m" (set the memory size to use)
--restart=always (restart if the container fail)
--restart=on-failure:3 (try 3 times if fail)
prune (kill all existed containers)


Useful tips:
> docker            (just type docker then enter, it will show the available option)
> docker image      (just type "docker image" then enter, it will show the avaiable option)



Docker Instruction Formats:
* Shell Form
The commands specified as arguments of the CMD instruction run inside a shell. Here is an example of the CMD instruction with arguments in shell form:
CMD echo "We are learning about Dockerfile"
On Linux, the instruction would look like this:
/bin/sh -c echo "We are learning about Dockerfile"
The default shell on Linux is /bin/sh/ -c. However, we can change the default shell with the SHELL​ instruction of the Dockerfile.
* Exec Form
In this form, the binary/program is run directly, without a shell. Here is an example of the CMD instruction with arguments in exec form:
CMD ["/bin/echo", "We are learning about Dockerfile"]
The binary /bin/echo​ runs directly inside the container, and participates in the build process. Between the two forms, the Exec Form is preferred by users.


Dockerfile Instructions
https://docs.docker.com/engine/reference/builder/
The instructions can be divided into two distinct categories - build time and run time instructions.
build time: FORM, ARG, RUN, LABEL, EXPOSE, COPY, ADD, WORKDIR, ENV, VOLUME, USER, ONBUILD, STOPSIGNAL, HEALTHCHECK, SHELL​
run time: CMD, ENTRYPOINT
If we want to exclude some files and directories during the ​ docker image build​ process, then we should list them in the .dockerignore​ file in the referenced folder:
> cat .dockerignore
code
tmp
test.py
The above .dockerignore file list all the thing which is going to exclude in the build process.


Docker Networking
https://docs.docker.com/network/#docker-ee-networking-features
Regardless of the network type and driver combination used to implement the container networking, Docker is able to manage traffic to and from containers by editing iptables and server routing rules, while providing advanced features such as packet encapsulation, encryption, routing mesh and session affinity.

Docker Networking Drivers
1. bridge
The default network type that Docker containers attach to is the bridge network, implemented by the bridge driver. 
The main roles of a bridge network are to isolate the container network from the host system network, and to act as a DHCP server and assign unique IP addresses to containers as they are running attached to the bridge. 
This is a useful feature when containers of an application need to talk to each other while they all run on the same host system. Other features of bridge networks depend whether the bridge is default or user-defined. 
Most often, a user-defined bridge presents advantages over the default bridge, such as better traffic isolation, automatic DNS resolution, on-the-fly container connection/disconnection to and from the network, advanced and flexible configuration options, and even sharing of environment variables between containers.
2. host
The host network driver option, as opposed to the bridge, eliminates the network isolation between the container and the host system by allowing the container to directly access the host network. 
In addition, it may help with performance optimization by eliminating the need for Network Address Translation (NAT) or proxying since the container ports are automatically published and available as host ports.
3. overlay
Gaining a lot of popularity these days is the overlay network type supported by the overlay driver. It is the network type that spans multiple hosts, typically part of a cluster, allowing the containers' traffic to be routed between hosts as containers or services from one host attempt to talk to others running on another host in the cluster.
This network type is very popular with container orchestration platforms because it not only enables traffic across the entire cluster of host systems, but also provides traffic isolation and management through rules and policies.
4. macvlan
The macvlan network driver allows a user to change the appearance of a container on the physical network. A container may appear as a physical device with its own MAC address on the network, thus enabling the container to be directly connected to the physical network instead of having its traffic routed through the host network.
5. none
The none driver option for container networking disables the networking of a container while allowing the very same container to use a custom third-party network driver, if needed, to implement its networking requirements.
6. network plugin
Network plugins expand the capabilities of Docker through third-party network drivers that integrate Docker with specialized network stacks. Certain network plugins may combine features otherwise available from single network drivers while improving network resiliency and policy management.



# Network command
> docker network ls (there are 3 networks created by default; they are the bridge, host and none)
> docker network inspect <network_id> (you should see "subnet":"172.17.0.0/16"; also the containers IP)

# Example: create 2 container and try to ping each other
# Newly created container must be attached to the default bridge network
> sudo docker run -it --name con01 alpine sh
> sudo docker run -it --name con02 alpine sh
> sudo docker network ls
> sudo docker network inspect <default_bridge_network_id> (you can see the 2 containers is attached to this network)
> sudo docker attach con01 (try to pint the container con02)






Container storage
UnionFS is used by Docker to overlay a base container image with storage layers, such as ephemeral storage layer, custom storage layer, and config layer at the time a new container is created. 
The ephemeral storage is reserved for the container’s Input/Output (I/O) operations and it is not recommended to be used for persistent data; instead, a volume should be mounted on the container to provide persistent storage not managed by UnionFS.
The Copy-on-Write (CoW) strategy of UnionFS allows users to “indirectly” modify the content of files available to the running container from the base container image storage layer. While the container image files are Read-Only, when a user attempts to modify such a file, no errors or mechanisms will prevent the user from doing so. 
Instead, the base container image file is copied and saved on the ephemeral storage layer of the container and the user is allowed to make changes to the new copy of the file. In essence, a copy of a file is being saved when a user attempts to edit a Read-Only file of the base container image, all while the base container image file remains intact.

Applications and containers make use of two different types of data - ephemeral and persistent; therefore Docker takes separate approaches when managing ephemeral vs. persistent data.
Ephemeral data is data typically needed for a very short period of time, and there is no damage to the enterprise when that data is lost once the container is terminated and deleted. 
Ephemeral data is stored on ephemeral storage, which is specified and defined within the scope of the container, and; the ephemeral storage also gets deleted together with the container. 
For ephemeral data management, Docker provides a bind mount mechanism tied in with the host’s directory structure. The bind mount references a directory of the host system created on-demand if not existing when the container is created. 
One of the downsides of bind mounts is that they cannot be directly managed from the Docker CLI.

It is recommended, however, the use of a tmpfs mount for ephemeral data, not only to prevent the data from being stored permanently on the container’s writable storage layer, but also to increase the container’s performance.

Persistent data, however, is critical data that has to be stored in a location that provides data resilience, to then later be managed by an aggregator or other applications designed to process and manage critical data. 
Persistent data is recommended to be stored on external persistent volume mounts managed from the Docker CLI for easy backup and migration, flexibility, portability, sharing, and extended functionality. Persistent volumes are not managed by UnionFS, are not specified and defined only within the scope of a container, and do not get deleted together with the container.





# Container Storage: command
# Volume vs Bind Mode
# Volume is the suggested (official) way to use storage. The volume is created by the docker and stored in the default path "/var/lib/docker/volumes", you can't specify the path by yourself
# Bind mode: you can create the path in the host by yourself and map it to the docker 

# The following command is for volume
> docker container run -it --mount target=/data --name cvol alpine sh (this create a volume in /var/lib/docker/volumes/<docker_generated_id>/_data; <docker_generated_id> because source is not provided)
> docker container run -it -v /data --name cvol alpine sh  ("-v /data" is the short cut for "--mount target=/data")
> docker container run -it --mount source=mountvol,target=/data --name cmountvol alpine sh (this create a volume in /var/lib/docker/volumes/mountvol/_data; this time is not <docker_generated_d> because source is provided)
> docker container run -it -v mountvol:/data --name cmountvol alpine sh (same as above; "-v mountvol:/data" is short cut for "-mount source=mountvol,target=/data")
# display container details to view mounted volume
> docker container inspect cvol     (then check "Mounts:Name")
> ls /var/lib/docker/volumes/<the_name_checked_in_above_line>/_data
# list volumes
> docker volume ls
# create a named volume (those previous commands create the volume through container; this is create a volume directly)
> docker volume create --name myvol (docker create a volume in /var/lib/docker/volumes/myvol/_data)
> docker container run -it --mount source=myvol,target=/data --name cmyvol alpine sh (source=myvol, use the volume created in the previous command line)
# Remove a volume together with the container (the volume crated with the container; not created independently)
> docker container rm -f -v cvol (-v is to remove the volume together with the container; if the container removed without telling docker to remove the volume, the volume will be kept)
# Remove a volume
> docker volume ls
> docker volume rm <volume_name> (this will give an error if volume is in use)


# The folllowing command is for bind mode
> mkdir /mnt/shared (create a directory in the host for stroage)
> docker container run -it --mount type=bind,source=/mnt/shared,target=/data --name csharedvol alpine sh    (type=bind means bind mode; if not specify it's volume; bind mode can create a path in host; volume path is defualted by docker)
> mkdir /tmp/ro
> docker container run -it --mount type=bind,source=/tmp/ro,target=/data,readonly --name csharedvol alpine sh (readonly will make all the thing inside the container /data to be readonly; only the host can modify the file)

# system command on volume
> docker system df (check the disk space)
> docker volume prune (remove all unused volumes)

